{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPU_CIFAR10_Trainer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sbl1996/hanser/blob/master/examples/TPU_CIFAR10_Trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ4avtZ_T6Rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U git+https://github.com/sbl1996/hanser.git\n",
        "# !pip uninstall pillow -y\n",
        "# !pip install -U --force-reinstall pillow-simd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRd0qDpd5Y90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import tensorflow as tf\n",
        "from hanser.tpu import get_colab_tpu, auth\n",
        "\n",
        "tpu = get_colab_tpu()\n",
        "use_tpu = tpu is not None\n",
        "if use_tpu:\n",
        "    strategy = tf.contrib.distribute.TPUStrategy(tpu)    \n",
        "    auth()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kULr4nHq1PX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "import math\n",
        "import time\n",
        "from toolz import curry\n",
        "\n",
        "from tensorflow.keras.metrics import Mean, SparseCategoricalAccuracy\n",
        "\n",
        "from hanser.datasets import prepare\n",
        "from hanser.train import Trainer\n",
        "from hanser.model.cifar import pyramidnet\n",
        "from hanser.train.callbacks import cosine_lr\n",
        "from hanser.transform import random_crop, cutout, normalize, to_tensor\n",
        "from hanser.transform.autoaugment import autoaugment\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOuq3nUi9bQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(example_proto):\n",
        "    features = {\n",
        "        'image': tf.io.FixedLenFeature((), tf.string, default_value=''),\n",
        "        'label': tf.io.FixedLenFeature((), tf.int64, default_value=0),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example_proto, features)\n",
        "    x = tf.decode_raw(example['image'], tf.uint8)\n",
        "    x = tf.reshape(x, (32, 32, 3))\n",
        "    y = example['label']\n",
        "    return x, y\n",
        "\n",
        "\n",
        "@curry\n",
        "def preprocess(example, training):\n",
        "    image, label = decode(example)\n",
        "\n",
        "    if training:\n",
        "        image = random_crop(image, (32, 32), (4, 4))\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "        image = autoaugment(image, \"CIFAR10\")\n",
        "\n",
        "    image, label = to_tensor(image, label)\n",
        "    image = normalize(image, [0.4914, 0.4822, 0.4465], [0.2470, 0.2435, 0.2616])\n",
        "\n",
        "    if training:\n",
        "        image = cutout(image, 16)\n",
        "\n",
        "    return image, label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2LpPULQ0Noq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_files = !gsutil ls -r gs://hrvvi-datasets/CIFAR10/train* | cat\n",
        "test_files = !gsutil ls -r gs://hrvvi-datasets/CIFAR10/test* | cat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw02eCR6xyEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train_examples = 45000\n",
        "num_val_examples = 5000\n",
        "num_test_examples = 10000\n",
        "batch_size = 128 * 8\n",
        "eval_batch_size = batch_size * 2\n",
        "steps_per_epoch = num_train_examples // batch_size\n",
        "val_steps = math.ceil(num_val_examples / eval_batch_size)\n",
        "test_steps = math.ceil(num_test_examples / eval_batch_size)\n",
        "\n",
        "ds = tf.data.TFRecordDataset(train_files)\n",
        "ds_train = prepare(\n",
        "    ds.take(num_train_examples), preprocess(training=True),\n",
        "    batch_size, training=True, buffer_size=10000)\n",
        "ds_val = prepare(\n",
        "    ds.skip(num_train_examples), preprocess(training=False),\n",
        "    eval_batch_size, training=False)\n",
        "ds_test = prepare(\n",
        "    tf.data.TFRecordDataset(test_files), preprocess(training=False),\n",
        "    eval_batch_size, training=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkAGTIuD1bR9",
        "colab_type": "code",
        "outputId": "27ea2c50-e6c8-41d7-906d-d36ac41bcf09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "with strategy.scope():\n",
        "    input_shape = (32, 32, 3)\n",
        "    model = pyramidnet(input_shape, 10, 16, 270, [18, 18, 18])\n",
        "    criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.1 * 8, momentum=0.9, nesterov=True)\n",
        "    lr_schedule = cosine_lr(base_lr=0.1 * 8, total_epochs=600, warmup=10, gamma=1/8)\n",
        "\n",
        "    training_loss = Mean('loss', dtype=tf.float32)\n",
        "    training_accuracy = SparseCategoricalAccuracy('acc', dtype=tf.float32)\n",
        "    test_loss = Mean('loss', dtype=tf.float32)\n",
        "    test_accuracy = SparseCategoricalAccuracy('acc', dtype=tf.float32)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VspYEPVgxTnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = Trainer(model, criterion, optimizer, lr_schedule,\n",
        "                  metrics=[training_loss, training_accuracy],\n",
        "                  test_metrics=[test_loss, test_accuracy],\n",
        "                  tpu=tpu, strategy=strategy, model_dir=\"gs://hrvvi-models/checkpoints/cifar10-pyramidnet\",\n",
        "                  weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpnobXMsxUap",
        "colab_type": "code",
        "outputId": "e5f23f66-d2cb-4582-e5eb-4b03d5aabff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainer.train_and_evaluate(\n",
        "    600, ds_train, steps_per_epoch, ds_val, val_steps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/hanser/train/trainer.py:138: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/hanser/train/trainer.py:140: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Initializing from scratch.\n",
            "Epoch 1\n",
            "Train \tcost: 96s, loss: 1.942, acc: 0.287\n",
            "Val \tcost: 36s, loss: 1.742, acc: 0.406\n",
            "Epoch 2\n",
            "Train \tcost: 15s, loss: 1.566, acc: 0.436\n",
            "Val \tcost: 0s, loss: 1.645, acc: 0.497\n",
            "Epoch 3\n",
            "Train \tcost: 15s, loss: 1.335, acc: 0.522\n",
            "Val \tcost: 0s, loss: 1.106, acc: 0.629\n",
            "Epoch 4\n",
            "Train \tcost: 15s, loss: 1.171, acc: 0.586\n",
            "Val \tcost: 0s, loss: 1.424, acc: 0.586\n",
            "Epoch 5\n",
            "Train \tcost: 15s, loss: 1.050, acc: 0.633\n",
            "Val \tcost: 0s, loss: 0.849, acc: 0.725\n",
            "Epoch 6\n",
            "Train \tcost: 15s, loss: 0.953, acc: 0.667\n",
            "Val \tcost: 0s, loss: 0.697, acc: 0.774\n",
            "Epoch 7\n",
            "Train \tcost: 15s, loss: 0.885, acc: 0.690\n",
            "Val \tcost: 0s, loss: 0.785, acc: 0.749\n",
            "Epoch 8\n",
            "Train \tcost: 15s, loss: 0.853, acc: 0.702\n",
            "Val \tcost: 0s, loss: 0.712, acc: 0.765\n",
            "Epoch 9\n",
            "Train \tcost: 15s, loss: 0.795, acc: 0.722\n",
            "Val \tcost: 0s, loss: 0.547, acc: 0.818\n",
            "Epoch 10\n",
            "Train \tcost: 15s, loss: 0.772, acc: 0.733\n",
            "Val \tcost: 0s, loss: 0.434, acc: 0.856\n",
            "Epoch 11\n",
            "Train \tcost: 15s, loss: 0.734, acc: 0.744\n",
            "Val \tcost: 0s, loss: 0.681, acc: 0.786\n",
            "Epoch 12\n",
            "Train \tcost: 15s, loss: 0.690, acc: 0.760\n",
            "Val \tcost: 0s, loss: 0.444, acc: 0.846\n",
            "Epoch 13\n",
            "Train \tcost: 15s, loss: 0.658, acc: 0.769\n",
            "Val \tcost: 0s, loss: 0.422, acc: 0.856\n",
            "Epoch 14\n",
            "Train \tcost: 15s, loss: 0.639, acc: 0.778\n",
            "Val \tcost: 0s, loss: 0.405, acc: 0.858\n",
            "Epoch 15\n",
            "Train \tcost: 15s, loss: 0.615, acc: 0.788\n",
            "Val \tcost: 0s, loss: 0.409, acc: 0.862\n",
            "Epoch 16\n",
            "Train \tcost: 15s, loss: 0.593, acc: 0.794\n",
            "Val \tcost: 0s, loss: 0.396, acc: 0.862\n",
            "Epoch 17\n",
            "Train \tcost: 15s, loss: 0.575, acc: 0.800\n",
            "Val \tcost: 0s, loss: 0.330, acc: 0.887\n",
            "Epoch 18\n",
            "Train \tcost: 15s, loss: 0.565, acc: 0.803\n",
            "Val \tcost: 0s, loss: 0.351, acc: 0.886\n",
            "Epoch 19\n",
            "Train \tcost: 15s, loss: 0.550, acc: 0.807\n",
            "Val \tcost: 0s, loss: 0.305, acc: 0.897\n",
            "Epoch 20\n",
            "Train \tcost: 15s, loss: 0.535, acc: 0.814\n",
            "Val \tcost: 0s, loss: 0.440, acc: 0.853\n",
            "Epoch 21\n",
            "Train \tcost: 15s, loss: 0.524, acc: 0.817\n",
            "Val \tcost: 0s, loss: 0.317, acc: 0.890\n",
            "Epoch 22\n",
            "Train \tcost: 15s, loss: 0.512, acc: 0.821\n",
            "Val \tcost: 0s, loss: 0.403, acc: 0.871\n",
            "Epoch 23\n",
            "Train \tcost: 15s, loss: 0.506, acc: 0.825\n",
            "Val \tcost: 0s, loss: 0.353, acc: 0.883\n",
            "Epoch 24\n",
            "Train \tcost: 15s, loss: 0.499, acc: 0.826\n",
            "Val \tcost: 0s, loss: 0.295, acc: 0.898\n",
            "Epoch 25\n",
            "Train \tcost: 15s, loss: 0.483, acc: 0.832\n",
            "Val \tcost: 0s, loss: 0.332, acc: 0.894\n",
            "Epoch 26\n",
            "Train \tcost: 15s, loss: 0.476, acc: 0.835\n",
            "Val \tcost: 0s, loss: 0.275, acc: 0.908\n",
            "Epoch 27\n",
            "Train \tcost: 15s, loss: 0.462, acc: 0.837\n",
            "Val \tcost: 0s, loss: 0.328, acc: 0.894\n",
            "Epoch 28\n",
            "Train \tcost: 15s, loss: 0.454, acc: 0.842\n",
            "Val \tcost: 0s, loss: 0.251, acc: 0.914\n",
            "Epoch 29\n",
            "Train \tcost: 15s, loss: 0.455, acc: 0.841\n",
            "Val \tcost: 0s, loss: 0.253, acc: 0.920\n",
            "Epoch 30\n",
            "Train \tcost: 15s, loss: 0.443, acc: 0.845\n",
            "Val \tcost: 0s, loss: 0.250, acc: 0.916\n",
            "Epoch 31\n",
            "Train \tcost: 15s, loss: 0.439, acc: 0.846\n",
            "Val \tcost: 0s, loss: 0.251, acc: 0.915\n",
            "Epoch 32\n",
            "Train \tcost: 15s, loss: 0.432, acc: 0.849\n",
            "Val \tcost: 0s, loss: 0.326, acc: 0.899\n",
            "Epoch 33\n",
            "Train \tcost: 15s, loss: 0.426, acc: 0.852\n",
            "Val \tcost: 0s, loss: 0.235, acc: 0.919\n",
            "Epoch 34\n",
            "Train \tcost: 15s, loss: 0.422, acc: 0.853\n",
            "Val \tcost: 0s, loss: 0.281, acc: 0.907\n",
            "Epoch 35\n",
            "Train \tcost: 15s, loss: 0.415, acc: 0.855\n",
            "Val \tcost: 0s, loss: 0.272, acc: 0.910\n",
            "Epoch 36\n",
            "Train \tcost: 15s, loss: 0.417, acc: 0.854\n",
            "Val \tcost: 0s, loss: 0.213, acc: 0.928\n",
            "Epoch 37\n",
            "Train \tcost: 15s, loss: 0.405, acc: 0.857\n",
            "Val \tcost: 0s, loss: 0.255, acc: 0.911\n",
            "Epoch 38\n",
            "Train \tcost: 15s, loss: 0.402, acc: 0.859\n",
            "Val \tcost: 0s, loss: 0.269, acc: 0.912\n",
            "Epoch 39\n",
            "Train \tcost: 15s, loss: 0.397, acc: 0.861\n",
            "Val \tcost: 0s, loss: 0.255, acc: 0.913\n",
            "Epoch 40\n",
            "Train \tcost: 15s, loss: 0.393, acc: 0.862\n",
            "Val \tcost: 0s, loss: 0.211, acc: 0.931\n",
            "Epoch 41\n",
            "Train \tcost: 15s, loss: 0.389, acc: 0.865\n",
            "Val \tcost: 0s, loss: 0.210, acc: 0.927\n",
            "Epoch 42\n",
            "Train \tcost: 15s, loss: 0.383, acc: 0.865\n",
            "Val \tcost: 0s, loss: 0.245, acc: 0.922\n",
            "Epoch 43\n",
            "Train \tcost: 15s, loss: 0.382, acc: 0.867\n",
            "Val \tcost: 0s, loss: 0.247, acc: 0.920\n",
            "Epoch 44\n",
            "Train \tcost: 15s, loss: 0.372, acc: 0.869\n",
            "Val \tcost: 0s, loss: 0.250, acc: 0.920\n",
            "Epoch 45\n",
            "Train \tcost: 15s, loss: 0.372, acc: 0.868\n",
            "Val \tcost: 0s, loss: 0.257, acc: 0.923\n",
            "Epoch 46\n",
            "Train \tcost: 15s, loss: 0.364, acc: 0.874\n",
            "Val \tcost: 0s, loss: 0.212, acc: 0.928\n",
            "Epoch 47\n",
            "Train \tcost: 15s, loss: 0.366, acc: 0.873\n",
            "Val \tcost: 0s, loss: 0.282, acc: 0.915\n",
            "Epoch 48\n",
            "Train \tcost: 15s, loss: 0.354, acc: 0.877\n",
            "Val \tcost: 0s, loss: 0.232, acc: 0.927\n",
            "Epoch 49\n",
            "Train \tcost: 15s, loss: 0.361, acc: 0.873\n",
            "Val \tcost: 0s, loss: 0.230, acc: 0.924\n",
            "Epoch 50\n",
            "Train \tcost: 15s, loss: 0.360, acc: 0.874\n",
            "Val \tcost: 0s, loss: 0.235, acc: 0.927\n",
            "Epoch 51\n",
            "Train \tcost: 15s, loss: 0.351, acc: 0.876\n",
            "Val \tcost: 0s, loss: 0.213, acc: 0.929\n",
            "Epoch 52\n",
            "Train \tcost: 15s, loss: 0.352, acc: 0.879\n",
            "Val \tcost: 0s, loss: 0.242, acc: 0.924\n",
            "Epoch 53\n",
            "Train \tcost: 15s, loss: 0.342, acc: 0.880\n",
            "Val \tcost: 0s, loss: 0.208, acc: 0.932\n",
            "Epoch 54\n",
            "Train \tcost: 15s, loss: 0.344, acc: 0.881\n",
            "Val \tcost: 0s, loss: 0.223, acc: 0.926\n",
            "Epoch 55\n",
            "Train \tcost: 15s, loss: 0.338, acc: 0.881\n",
            "Val \tcost: 0s, loss: 0.215, acc: 0.930\n",
            "Epoch 56\n",
            "Train \tcost: 15s, loss: 0.346, acc: 0.879\n",
            "Val \tcost: 0s, loss: 0.207, acc: 0.933\n",
            "Epoch 57\n",
            "Train \tcost: 15s, loss: 0.339, acc: 0.881\n",
            "Val \tcost: 0s, loss: 0.237, acc: 0.928\n",
            "Epoch 58\n",
            "Train \tcost: 15s, loss: 0.338, acc: 0.881\n",
            "Val \tcost: 0s, loss: 0.237, acc: 0.932\n",
            "Epoch 59\n",
            "Train \tcost: 15s, loss: 0.338, acc: 0.881\n",
            "Val \tcost: 0s, loss: 0.199, acc: 0.938\n",
            "Epoch 60\n",
            "Train \tcost: 15s, loss: 0.326, acc: 0.887\n",
            "Val \tcost: 0s, loss: 0.217, acc: 0.931\n",
            "Epoch 61\n",
            "Train \tcost: 15s, loss: 0.333, acc: 0.884\n",
            "Val \tcost: 0s, loss: 0.203, acc: 0.928\n",
            "Epoch 62\n",
            "Train \tcost: 15s, loss: 0.319, acc: 0.889\n",
            "Val \tcost: 0s, loss: 0.236, acc: 0.929\n",
            "Epoch 63\n",
            "Train \tcost: 15s, loss: 0.321, acc: 0.887\n",
            "Val \tcost: 0s, loss: 0.204, acc: 0.932\n",
            "Epoch 64\n",
            "Train \tcost: 15s, loss: 0.321, acc: 0.889\n",
            "Val \tcost: 0s, loss: 0.192, acc: 0.937\n",
            "Epoch 65\n",
            "Train \tcost: 15s, loss: 0.318, acc: 0.888\n",
            "Val \tcost: 0s, loss: 0.209, acc: 0.937\n",
            "Epoch 66\n",
            "Train \tcost: 15s, loss: 0.316, acc: 0.888\n",
            "Val \tcost: 0s, loss: 0.221, acc: 0.928\n",
            "Epoch 67\n",
            "Train \tcost: 15s, loss: 0.320, acc: 0.887\n",
            "Val \tcost: 0s, loss: 0.206, acc: 0.939\n",
            "Epoch 68\n",
            "Train \tcost: 15s, loss: 0.312, acc: 0.890\n",
            "Val \tcost: 0s, loss: 0.232, acc: 0.932\n",
            "Epoch 69\n",
            "Train \tcost: 15s, loss: 0.307, acc: 0.894\n",
            "Val \tcost: 0s, loss: 0.199, acc: 0.930\n",
            "Epoch 70\n",
            "Train \tcost: 15s, loss: 0.303, acc: 0.893\n",
            "Val \tcost: 0s, loss: 0.225, acc: 0.931\n",
            "Epoch 71\n",
            "Train \tcost: 15s, loss: 0.306, acc: 0.893\n",
            "Val \tcost: 0s, loss: 0.228, acc: 0.932\n",
            "Epoch 72\n",
            "Train \tcost: 15s, loss: 0.296, acc: 0.895\n",
            "Val \tcost: 0s, loss: 0.232, acc: 0.928\n",
            "Epoch 73\n",
            "Train \tcost: 15s, loss: 0.300, acc: 0.896\n",
            "Val \tcost: 0s, loss: 0.176, acc: 0.944\n",
            "Epoch 74\n",
            "Train \tcost: 15s, loss: 0.300, acc: 0.896\n",
            "Val \tcost: 0s, loss: 0.226, acc: 0.929\n",
            "Epoch 75\n",
            "Train \tcost: 15s, loss: 0.298, acc: 0.895\n",
            "Val \tcost: 0s, loss: 0.224, acc: 0.932\n",
            "Epoch 76\n",
            "Train \tcost: 15s, loss: 0.296, acc: 0.897\n",
            "Val \tcost: 0s, loss: 0.257, acc: 0.924\n",
            "Epoch 77\n",
            "Train \tcost: 15s, loss: 0.299, acc: 0.895\n",
            "Val \tcost: 0s, loss: 0.175, acc: 0.945\n",
            "Epoch 78\n",
            "Train \tcost: 15s, loss: 0.284, acc: 0.899\n",
            "Val \tcost: 0s, loss: 0.205, acc: 0.934\n",
            "Epoch 79\n",
            "Train \tcost: 15s, loss: 0.292, acc: 0.897\n",
            "Val \tcost: 0s, loss: 0.206, acc: 0.935\n",
            "Epoch 80\n",
            "Train \tcost: 15s, loss: 0.292, acc: 0.897\n",
            "Val \tcost: 0s, loss: 0.186, acc: 0.938\n",
            "Epoch 81\n",
            "Train \tcost: 15s, loss: 0.291, acc: 0.900\n",
            "Val \tcost: 0s, loss: 0.209, acc: 0.933\n",
            "Epoch 82\n",
            "Train \tcost: 15s, loss: 0.283, acc: 0.900\n",
            "Val \tcost: 0s, loss: 0.223, acc: 0.935\n",
            "Epoch 83\n",
            "Train \tcost: 15s, loss: 0.287, acc: 0.900\n",
            "Val \tcost: 0s, loss: 0.188, acc: 0.942\n",
            "Epoch 84\n",
            "Train \tcost: 15s, loss: 0.285, acc: 0.902\n",
            "Val \tcost: 0s, loss: 0.188, acc: 0.941\n",
            "Epoch 85\n",
            "Train \tcost: 15s, loss: 0.281, acc: 0.900\n",
            "Val \tcost: 0s, loss: 0.211, acc: 0.932\n",
            "Epoch 86\n",
            "Train \tcost: 15s, loss: 0.279, acc: 0.902\n",
            "Val \tcost: 0s, loss: 0.196, acc: 0.939\n",
            "Epoch 87\n",
            "Train \tcost: 15s, loss: 0.286, acc: 0.900\n",
            "Val \tcost: 0s, loss: 0.194, acc: 0.940\n",
            "Epoch 88\n",
            "Train \tcost: 15s, loss: 0.279, acc: 0.903\n",
            "Val \tcost: 0s, loss: 0.178, acc: 0.942\n",
            "Epoch 89\n",
            "Train \tcost: 15s, loss: 0.279, acc: 0.903\n",
            "Val \tcost: 0s, loss: 0.182, acc: 0.944\n",
            "Epoch 90\n",
            "Train \tcost: 15s, loss: 0.277, acc: 0.904\n",
            "Val \tcost: 0s, loss: 0.186, acc: 0.943\n",
            "Epoch 91\n",
            "Train \tcost: 15s, loss: 0.278, acc: 0.903\n",
            "Val \tcost: 0s, loss: 0.186, acc: 0.940\n",
            "Epoch 92\n",
            "Train \tcost: 15s, loss: 0.269, acc: 0.906\n",
            "Val \tcost: 0s, loss: 0.225, acc: 0.928\n",
            "Epoch 93\n",
            "Train \tcost: 15s, loss: 0.276, acc: 0.905\n",
            "Val \tcost: 0s, loss: 0.185, acc: 0.945\n",
            "Epoch 94\n",
            "Train \tcost: 15s, loss: 0.268, acc: 0.905\n",
            "Val \tcost: 0s, loss: 0.184, acc: 0.943\n",
            "Epoch 95\n",
            "Train \tcost: 15s, loss: 0.269, acc: 0.906\n",
            "Val \tcost: 0s, loss: 0.204, acc: 0.938\n",
            "Epoch 96\n",
            "Train \tcost: 15s, loss: 0.266, acc: 0.906\n",
            "Val \tcost: 0s, loss: 0.246, acc: 0.929\n",
            "Epoch 97\n",
            "Train \tcost: 15s, loss: 0.274, acc: 0.904\n",
            "Val \tcost: 0s, loss: 0.170, acc: 0.946\n",
            "Epoch 98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STg54uWDXuyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.evaluate(ds_test, test_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}